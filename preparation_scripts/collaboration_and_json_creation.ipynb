{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76fd669a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusion termin√©e ! Le fichier final contient 120 chercheurs.\n",
      "Fichier sauvegard√© sous : ArtHistory_Final_Merged.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_clean = pd.read_csv(\"ArtHistory_Openalex_with_macro_tags_clean.csv\")\n",
    "df_llm = pd.read_csv(\"ArtHistory_Openalex_with_llm_study_tags.csv\")\n",
    "\n",
    "df_clean['openalex_author_id'] = df_clean['openalex_author_id'].astype(str).str.strip()\n",
    "df_llm['openalex_author_id'] = df_llm['openalex_author_id'].astype(str).str.strip()\n",
    "\n",
    "df_merged = pd.merge(\n",
    "    df_clean,\n",
    "    df_llm,\n",
    "    on='openalex_author_id',\n",
    "    how='left',\n",
    "    suffixes=('', '_from_llm')\n",
    ")\n",
    "\n",
    "mask_missing = df_merged['llm_study_tags'].isna()\n",
    "name_to_tags = df_llm.set_index('name')['llm_study_tags'].to_dict()\n",
    "df_merged.loc[mask_missing, 'llm_study_tags'] = df_merged.loc[mask_missing, 'name'].map(name_to_tags)\n",
    "df_merged.to_csv(\"ArtHistory_Final_Merged.csv\", index=False)\n",
    "\n",
    "print(f\"Fusion termin√©e ! Le fichier final contient {len(df_merged)} chercheurs.\")\n",
    "print(\"Fichier sauvegard√© sous : ArtHistory_Final_Merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fce207dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D√©but de l'enrichissement cibl√©...\n",
      "--> Traitement de Mike Pope (Collab d√©tect√©e !)\n",
      "--> Traitement de Marlene Hansen Esplin (Collab d√©tect√©e !)\n",
      "--> Traitement de Jeffrey F. Hamburger (Collab d√©tect√©e !)\n",
      "--> Traitement de Alina Payne (Collab d√©tect√©e !)\n",
      "--> Traitement de Sarah Lewis (Collab d√©tect√©e !)\n",
      "--> Traitement de Christina Maranci (Collab d√©tect√©e !)\n",
      "--> Traitement de Usha Iyer (Collab d√©tect√©e !)\n",
      "--> Traitement de Ziliang Liu (Collab d√©tect√©e !)\n",
      "--> Traitement de Amy A. McKenna (Collab d√©tect√©e !)\n",
      " Institutions trouv√©es : IFP √ânergies nouvelles\n",
      "--> Traitement de Kern Samuel (Collab d√©tect√©e !)\n",
      "--> Traitement de Xiaotian Yin (Collab d√©tect√©e !)\n",
      " Institutions trouv√©es : Institut national de recherche en informatique et en automatique; Centre Inria de l'Universit√© de Lorraine; Laboratoire Lorrain de Recherche en Informatique et ses Applications\n",
      "--> Traitement de Ben Benedict (Collab d√©tect√©e !)\n",
      " Institutions trouv√©es : Fondation pour l‚Äôinnovation en Cadiom√©tabolisme et Nutrition; Sanofi (France); Inserm; Centre Hospitalier Universitaire de Tours; Piti√©-Salp√™tri√®re Hospital; HRA Pharma (France); Universit√© de Tours; Clinique Pasteur; Sorbonne Universit√©\n",
      "--> Traitement de Tina Bawden (Collab d√©tect√©e !)\n",
      "--> Traitement de David Doris (Collab d√©tect√©e !)\n",
      "--> Traitement de Lihong Liu (Collab d√©tect√©e !)\n",
      "--> Traitement de Bryan K. Miller (Collab d√©tect√©e !)\n",
      " Institutions trouv√©es : Arch√©orient; AMIS - Laboratoire d'anthropologie mol√©culaire et imagerie de synth√®se; Universit√© de Toulouse; Arch√©ozoologie et Arch√©obotanique; Centre National de la Recherche Scientifique; Universit√© de Bordeaux; De la Pr√©histoire √† l'Actuel : Culture, Environnement et Anthropologie; Universit√© Toulouse III - Paul Sabatier; Institut des Mondes Africains\n",
      "\n",
      "Fini ! 16 chercheurs enrichis avec les d√©tails institutionnels.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import ast \n",
    "\n",
    "EMAIL_CONTACT = \"nina.vivierbarte@psl.eu\" \n",
    "df = pd.read_csv(\"ArtHistory_Final_Merged.csv\")\n",
    "\n",
    "if 'french_institution_names' not in df.columns:\n",
    "    df['french_institution_names'] = \"\"\n",
    "if 'french_collab_topics' not in df.columns:\n",
    "    df['french_collab_topics'] = \"\"\n",
    "\n",
    "def get_collab_details(author_id):\n",
    "    \"\"\"R√©cup√®re les institutions et topics fran√ßais pour un ID donn√©\"\"\"\n",
    "    clean_id = str(author_id).split('/')[-1]\n",
    "    url = f\"https://api.openalex.org/works?filter=author.id:{clean_id}\"\n",
    "    headers = {'User-Agent': f'mailto:{EMAIL_CONTACT}'}\n",
    "    \n",
    "    try:\n",
    "        r = requests.get(url, headers=headers)\n",
    "        if r.status_code != 200: return None, None\n",
    "        \n",
    "        data = r.json()\n",
    "        insts = set()\n",
    "        topics = set()\n",
    "        \n",
    "        for work in data.get('results', []):\n",
    "            is_french = False\n",
    "            for authorship in work.get('authorships', []):\n",
    "                for institution in authorship.get('institutions', []):\n",
    "                    if institution.get('country_code') == 'FR':\n",
    "                        insts.add(institution.get('display_name'))\n",
    "                        is_french = True\n",
    "            if is_french:\n",
    "                for t in work.get('topics', []):\n",
    "                    topics.add(t.get('display_name'))\n",
    "                    \n",
    "        return \"; \".join(insts), \"; \".join(topics)\n",
    "    except:\n",
    "        return None, None\n",
    "\n",
    "print(\"D√©but de l'enrichissement cibl√©...\")\n",
    "count = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    collab_status = str(row['openalex_france_collab']).lower()\n",
    "    if collab_status not in ['no', 'nan', '[]'] and pd.notna(row['openalex_author_id']):\n",
    "        \n",
    "        print(f\"--> Traitement de {row['name']} (Collab d√©tect√©e !)\")\n",
    "        \n",
    "        institutions, topics = get_collab_details(row['openalex_author_id'])\n",
    "        \n",
    "        if institutions:\n",
    "            df.at[index, 'french_institution_names'] = institutions\n",
    "            print(f\" Institutions trouv√©es : {institutions}\")\n",
    "        if topics:\n",
    "            df.at[index, 'french_collab_topics'] = topics\n",
    "            \n",
    "        count += 1\n",
    "        time.sleep(0.1)\n",
    "\n",
    "df.to_csv(\"ArtHistory_Final_With_Institutions.csv\", index=False)\n",
    "print(f\"\\nFini ! {count} chercheurs enrichis avec les d√©tails institutionnels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76b99067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier nettoy√© et enrichi : ArtHistory_Viz_Ready.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"ArtHistory_Final_With_Institutions.csv\")\n",
    "\n",
    "\n",
    "keep_cols = [\n",
    "    'name', 'university', 'openalex_author_id', 'openalex_works_count',\n",
    "    'macro_tags',           \n",
    "    'llm_study_tags',        \n",
    "    'openalex_france_collab', \n",
    "    'french_institution_names', \n",
    "    'french_collab_topics',\n",
    "    'link_france'         \n",
    "]\n",
    "df_clean = df[keep_cols].copy()\n",
    "\n",
    "french_keywords = ['france', 'french', 'paris', 'normandy', 'provence', 'loire', 'versailles', 'louvre', 'bordeaux', 'lyon']\n",
    "\n",
    "def extract_french_focus(tags_str):\n",
    "    if pd.isna(tags_str): return \"\"\n",
    "    tags = [t.strip() for t in str(tags_str).split(',')]\n",
    "    found = [t for t in tags if any(k in t.lower() for k in french_keywords)]\n",
    "    return \", \".join(found)\n",
    "\n",
    "df_clean['french_study_focus'] = df_clean['llm_study_tags'].apply(extract_french_focus)\n",
    "\n",
    "\n",
    "def get_type(row):\n",
    "    is_study = (str(row['link_france']).lower() == 'yes') or (len(row['french_study_focus']) > 2)\n",
    "    is_collab = str(row['openalex_france_collab']).lower() not in ['no', 'nan', '[]']\n",
    "    \n",
    "    if is_study and is_collab: return \"both\"\n",
    "    if is_collab: return \"collab\"\n",
    "    if is_study: return \"study\"\n",
    "    return \"none\"\n",
    "\n",
    "df_clean['france_connection_type'] = df_clean.apply(get_type, axis=1)\n",
    "\n",
    "df_clean.to_csv(\"ArtHistory_Viz_Ready.csv\", index=False)\n",
    "print(\"Fichier nettoy√© et enrichi : ArtHistory_Viz_Ready.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c6a39d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nettoyage de 12 homonymes scientifiques...\n",
      "\n",
      "Nombre final de vrais collaborateurs : 4\n",
      "                      name university  french_institution_names\n",
      "26   Marlene Hansen Esplin        BYU                       NaN\n",
      "50             Alina Payne    Harvard                       NaN\n",
      "59       Christina Maranci    Harvard                       NaN\n",
      "104            Tina Bawden   Michigan                       NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"ArtHistory_Viz_Ready.csv\")\n",
    "\n",
    "fake_collabs = [\n",
    "    \"Sarah Lewis\", \"Usha Iyer\", \"Ziliang Liu\", \"Amy A. McKenna\", \n",
    "    \"Mike Pope\", \"Kern Samuel\", \"Jeffrey F. Hamburger\",\n",
    " \n",
    "    \"Xiaotian Yin\",   \n",
    "    \"Ben Benedict\",    \n",
    "    \"David Doris\",   \n",
    "    \"Lihong Liu\",    \n",
    "    \"Bryan K. Miller\"  \n",
    "]\n",
    "\n",
    "print(f\"Nettoyage de {len(fake_collabs)} homonymes scientifiques...\")\n",
    "\n",
    "def clean_homonyms(row):\n",
    "    if row['name'] in fake_collabs:\n",
    "        row['openalex_france_collab'] = 'no'\n",
    "        row['french_institution_names'] = None\n",
    "        row['french_collab_topics'] = None\n",
    "    return row\n",
    "\n",
    "df_clean = df.apply(clean_homonyms, axis=1)\n",
    "\n",
    "def recalculate_type(row):\n",
    "    is_study = (str(row['link_france']).lower() == 'yes') or (len(str(row['french_study_focus'])) > 2)\n",
    "    is_collab = str(row['openalex_france_collab']).lower() not in ['no', 'nan', '[]', 'none']\n",
    "    \n",
    "    if is_study and is_collab: return \"both\" \n",
    "    if is_collab: return \"collab\"           \n",
    "    if is_study: return \"study\"              \n",
    "    return \"none\"                            \n",
    "\n",
    "df_clean['france_connection_type'] = df_clean.apply(recalculate_type, axis=1)\n",
    "\n",
    "true_collabs = df_clean[df_clean['france_connection_type'].isin(['collab', 'both'])]\n",
    "print(f\"\\nNombre final de vrais collaborateurs : {len(true_collabs)}\")\n",
    "print(true_collabs[['name', 'university', 'french_institution_names']])\n",
    "\n",
    "df_clean.to_csv(\"ArtHistory_Viz_Final_Cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "065a4a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D√©marrage de l'enqu√™te...\n",
      "\n",
      "üîç Analyse approfondie pour : Marlene Hansen Esplin (A5049988626)\n",
      "   -> Aucune trace explicite trouv√©e dans les m√©tadonn√©es.\n",
      "\n",
      "üîç Analyse approfondie pour : Alina Payne (A5038293506)\n",
      "   [COLLAB ] 2009 - \"Compositio and the Materiality of Architecture in the Italian Renaissance\"\n",
      "      -> Avec : √âcole Pratique des Hautes √âtudes\n",
      "\n",
      "üîç Analyse approfondie pour : Christina Maranci (A5064151424)\n",
      "   [COLLAB ] 2022 - \"Cultural Interactions in Medieval Georgia, Michele Bacci, Thomas Kaffenberger, Manuela¬†Studer-Karlen (√©d.)\"\n",
      "      -> Avec : Universit√© de Poitiers\n",
      "\n",
      "üîç Analyse approfondie pour : Tina Bawden (A5005450456)\n",
      "   -> Aucune trace explicite trouv√©e dans les m√©tadonn√©es.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "\n",
    "\n",
    "EMAIL = \"nina.vivierbarte@psl.eu\"  \n",
    "\n",
    "targets = [\n",
    "    {\"name\": \"Marlene Hansen Esplin\", \"id\": \"A5049988626\"},\n",
    "    {\"name\": \"Alina Payne\",           \"id\": \"A5038293506\"},\n",
    "    {\"name\": \"Christina Maranci\",     \"id\": \"A5064151424\"},\n",
    "    {\"name\": \"Tina Bawden\",           \"id\": \"A5005450456\"}\n",
    "]\n",
    "\n",
    "def deep_search_author(author_name, author_id):\n",
    "    print(f\"\\nüîç Analyse approfondie pour : {author_name} ({author_id})\")\n",
    "\n",
    "    clean_id = author_id.replace(\"https://openalex.org/\", \"\")\n",
    "\n",
    "    url = f\"https://api.openalex.org/works?filter=author.id:{clean_id}&per-page=200\"\n",
    "    headers = {'User-Agent': f'mailto:{EMAIL}'}\n",
    "    \n",
    "    try:\n",
    "        r = requests.get(url, headers=headers)\n",
    "        data = r.json()\n",
    "        \n",
    "        found_something = False\n",
    "        \n",
    "        for work in data.get('results', []):\n",
    "            title = work.get('title', 'Sans titre')\n",
    "            pub_year = work.get('publication_year')\n",
    "   \n",
    "            french_institutions = []\n",
    "            for authorship in work.get('authorships', []):\n",
    "                for inst in authorship.get('institutions', []):\n",
    "                    if inst.get('country_code') == 'FR':\n",
    "                        french_institutions.append(inst.get('display_name'))\n",
    "\n",
    "            has_french_title = any(kw in str(title).lower() for kw in ['france', 'french', 'paris', 'louvre'])\n",
    "\n",
    "            if french_institutions:\n",
    "                print(f\"   [COLLAB ] {pub_year} - \\\"{title}\\\"\")\n",
    "                print(f\"      -> Avec : {', '.join(set(french_institutions))}\")\n",
    "                found_something = True\n",
    "                \n",
    "            elif has_french_title:\n",
    "\n",
    "                print(f\"   [ETUDE ] {pub_year} - \\\"{title}\\\"\")\n",
    "                found_something = True\n",
    "\n",
    "        if not found_something:\n",
    "            print(\"   -> Aucune trace explicite trouv√©e dans les m√©tadonn√©es.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur API : {e}\")\n",
    "    \n",
    "    time.sleep(0.5) \n",
    "\n",
    "print(\"D√©marrage de l'enqu√™te...\")\n",
    "for t in targets:\n",
    "    deep_search_author(t['name'], t['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29662cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV Final g√©n√©r√© : ArtHistory_Final_Graph_Ready.csv\n",
      "G√©n√©ration du JSON...\n",
      "JSON Final g√©n√©r√© : network_data_final.json (300 noeuds, 1303 liens)\n",
      "\n",
      "--- Bilan des Types ---\n",
      "france_connection_type\n",
      "none      65\n",
      "study     52\n",
      "both       2\n",
      "collab     1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"ArtHistory_Viz_Final_Cleaned.csv\")\n",
    "\n",
    "sherlock_updates = {\n",
    "    \"Marlene Hansen Esplin\": {\n",
    "        \"status\": \"yes\",\n",
    "        \"institution\": \"Universit√© Bordeaux Montaigne\",\n",
    "        \"details\": \"Article: 'Reviews of Books' (2020)\"\n",
    "    },\n",
    "    \"Christina Maranci\": {\n",
    "        \"status\": \"yes\",\n",
    "        \"institution\": \"Universit√© de Poitiers\",\n",
    "        \"details\": \"Livre: 'Cultural Interactions in Medieval Georgia' (2022)\"\n",
    "    },\n",
    "    \"Alina Payne\": {\n",
    "        \"status\": \"yes\",\n",
    "        \"institution\": \"Ecole Pratique des Hautes Etudes, Universit√© Paris Sciences et Lettres\",\n",
    "        \"details\": \"Article: 'Compositio and the Materiality of Architecture in the Italian Renaissance' (2009)\"\n",
    "    },\n",
    "    \"Tina Bawden\": { \"status\": \"no\", \"institution\": None, \"details\": None }\n",
    "}\n",
    "\n",
    "def apply_updates(row):\n",
    "    name = row['name']\n",
    "    if name in sherlock_updates:\n",
    "        info = sherlock_updates[name]\n",
    "        \n",
    "        if info['status'] == 'yes':\n",
    "            row['openalex_france_collab'] = 'yes'\n",
    "            row['french_institution_names'] = info['institution']\n",
    "            current_topics = str(row['french_collab_topics']).replace('nan', '')\n",
    "            if info['details'] not in current_topics:\n",
    "                row['french_collab_topics'] = info['details']\n",
    "        else:\n",
    "            row['openalex_france_collab'] = 'no'\n",
    "            row['french_institution_names'] = None\n",
    "            row['french_collab_topics'] = None\n",
    "            \n",
    "    return row\n",
    "\n",
    "df_final = df.apply(apply_updates, axis=1)\n",
    "\n",
    "def get_final_type(row):\n",
    "    is_study = False\n",
    "    if str(row['link_france']).lower() == 'yes':\n",
    "        is_study = True\n",
    "    if pd.notna(row['french_study_focus']) and len(str(row['french_study_focus'])) > 3:\n",
    "        keywords = ['france', 'french', 'paris', 'bordeaux', 'poitiers', 'louvre', 'chartres']\n",
    "        if any(k in str(row['french_study_focus']).lower() for k in keywords):\n",
    "            is_study = True\n",
    "\n",
    "    is_collab = str(row['openalex_france_collab']).lower() in ['yes', 'true']\n",
    "    if pd.notna(row['french_institution_names']) and len(str(row['french_institution_names'])) > 2:\n",
    "        is_collab = True\n",
    "        \n",
    "    # Verdict\n",
    "    if is_study and is_collab: return \"both\"  \n",
    "    if is_collab: return \"collab\"             \n",
    "    if is_study: return \"study\"            \n",
    "    return \"none\"                           \n",
    "\n",
    "df_final['france_connection_type'] = df_final.apply(get_final_type, axis=1)\n",
    "\n",
    "df_final.to_csv(\"ArtHistory_Final_Graph_Ready.csv\", index=False)\n",
    "print(\"CSV Final g√©n√©r√© : ArtHistory_Final_Graph_Ready.csv\")\n",
    "\n",
    "\n",
    "nodes = []\n",
    "links = []\n",
    "existing_nodes = set()\n",
    "topic_counts = {}\n",
    "\n",
    "def add_node(id, group, type_node, attributes={}):\n",
    "    if id not in existing_nodes:\n",
    "        node = {\"id\": id, \"group\": group, \"type\": type_node}\n",
    "        node.update(attributes)\n",
    "        nodes.append(node)\n",
    "        existing_nodes.add(id)\n",
    "\n",
    "print(\"G√©n√©ration du JSON...\")\n",
    "\n",
    "for idx, row in df_final.iterrows():\n",
    "    researcher_name = row['name']\n",
    "\n",
    "    try:\n",
    "        works_count = int(row.get('openalex_works_count', 1))\n",
    "    except:\n",
    "        works_count = 1\n",
    "        \n",
    "    researcher_attrs = {\n",
    "        \"university\": row.get('university', 'Unknown'),\n",
    "        \"france_type\": row['france_connection_type'],\n",
    "        \"radius\": 5 + math.log(works_count + 1) * 2,\n",
    "\n",
    "        \"institutions\": str(row.get('french_institution_names', '')).replace('nan', ''),\n",
    "        \"study_focus\": str(row.get('french_study_focus', '')).replace('nan', '')\n",
    "    }\n",
    "    \n",
    "    add_node(researcher_name, row.get('university', 'Unknown'), \"researcher\", researcher_attrs)\n",
    "    tags = [t.strip() for t in str(row['macro_tags']).split(',')]\n",
    "    for tag in tags:\n",
    "        if not tag or tag.lower() == 'nan': continue\n",
    "\n",
    "        topic_counts[tag] = topic_counts.get(tag, 0) + 1\n",
    "\n",
    "        add_node(tag, \"Topic\", \"topic\", {\"france_type\": \"none\"}) \n",
    "        links.append({\"source\": researcher_name, \"target\": tag, \"value\": 1})\n",
    "\n",
    "for node in nodes:\n",
    "    if node['type'] == 'topic':\n",
    "        count = topic_counts.get(node['id'], 1)\n",
    "        node['radius'] = 3 + math.log(count + 1) * 3\n",
    "network_data = {\"nodes\": nodes, \"links\": links}\n",
    "\n",
    "with open('network_data_final.json', 'w') as f:\n",
    "    json.dump(network_data, f)\n",
    "\n",
    "print(f\"JSON Final g√©n√©r√© : network_data_final.json ({len(nodes)} noeuds, {len(links)} liens)\")\n",
    "print(\"\\n--- Bilan des Types ---\")\n",
    "print(df_final['france_connection_type'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
